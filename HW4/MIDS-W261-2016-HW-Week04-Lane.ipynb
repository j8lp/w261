{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASCI W261: Machine Learning at Scale\n",
    "## Assignment Week 4\n",
    "Jackson Lane (jelane@berkeley.edu) <br>\n",
    "W261-3 <br>\n",
    "# === INSTRUCTIONS for SUBMISSIONS ===\n",
    "Follow the instructions for submissions carefully.\n",
    "\n",
    "Submit your homework via the following form by  8:00AM of the following Tuesday (West Coast Time):\n",
    "\n",
    "https://docs.google.com/forms/d/1ZOr9RnIe_A06AcZDB6K1mJN4vrLeSmS2PD6Xm3eOiis/viewform?usp=send_form \n",
    "\n",
    "# === Week 4 ASSIGNMENTS ===\n",
    "\n",
    "# HW 4.0. \n",
    "#### What is MrJob? How is it different to Hadoop MapReduce? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MRJob is an abstraction that gives an abstraction of the MapReduce programming framework.  It was developed by Yelp but is now available for free to the public.  \n",
    "\n",
    "The main difference is that MRJob is an abstraction while Hadoop MapReduce is an actual implementation of the MapReduce programming paradigm.  You can run MRJob against multiple different MapReduce backends (Amazon EMR, Hadoop MapReduce, and Google Cloud Dataproc), whereas jobs written in Hadoop MapReduce can only run on Hadoop MapReduce.  Although MRJob does come with its own simple MapReduce implementation, the MRJob production use case is not to run jobs locally against this backend, but rather to run against a separate MapReduce implementation backend.  \n",
    "\n",
    "MrJob also provides a simpler way to write MapReduce jobs in Python versus someting like Hadoop Streaming.  Whereas in Hadoop Streaming you would need to write each mapper, combiner, and reducer as its own class file with a separate invocation for each MR step, in MRJob you can write everything in a single Python class file. MRJob also takes care of splitting up the key and value fields in the MapReduce outputs, whereas in Hadoop Streaming you would need to split up the key and value fields manually.  \n",
    "\n",
    "The drawback is that MRJob does not have as robust capabilities as Hadoop MapReduce.  In general, abstractions do not cover every functionality of their backend.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the mapper_init, mapper_final(), combiner_final(), reducer_final() methods? When are they called?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mapper_init (and the reduce_init) functions are all functions called once per node at the begining of the Map (and Reduce) stage in the MR Job. They are used to initialize counter variables or load other data sets for use in the main mapper method.    \n",
    "\n",
    "The mapper_final, combiner_final, and reducer_final methods are called after the mapper, combiner, and reducer phases, respectively.  They are used to tear down variables and clean up.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 4.1\n",
    "#### What is serialization in the context of MrJob or Hadoop? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serialization is how MRJob converts data to and from byes between each of the phases in a MapReduce job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### When it used in these frameworks? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's used to convert the input text into key value pairs for the mappers, to write mapper output to disk, to convert bytes received from the shuffle toto keys and values for reducer input, and to write key value pairs back to text for output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the default serialization mode for input and outputs for MrJob? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default serialization mode for input is RawValueProtocol.\n",
    "The default serialization mode for both internal communication and outputs is JSONProtocol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 4.2: Recall the Microsoft logfiles data from the async lecture. The logfiles are described are located at:\n",
    "\n",
    "https://kdd.ics.uci.edu/databases/msweb/msweb.html\n",
    "http://archive.ics.uci.edu/ml/machine-learning-databases/anonymous/\n",
    "\n",
    "This dataset records which areas (Vroots) of www.microsoft.com each user visited in a one-week timeframe in Feburary 1998.\n",
    "\n",
    " Here, you must preprocess the data on a single node (i.e., not on a cluster of nodes) from the format:\n",
    "\n",
    "- C,\"10001\",10001   #Visitor id 10001\n",
    "- V,1000,1          #Visit by Visitor 10001 to page id 1000\n",
    "- V,1001,1          #Visit by Visitor 10001 to page id 1001\n",
    "- V,1002,1          #Visit by Visitor 10001 to page id 1002\n",
    "- C,\"10002\",10002   #Visitor id 10001\n",
    "- V\n",
    "- Note: #denotes comments\n",
    "\n",
    "to the format:\n",
    "\n",
    "- V,1000,1,C, 10001\n",
    "- V,1001,1,C, 10001\n",
    "- V,1002,1,C, 10001\n",
    "\n",
    "Write the python code to accomplish this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import sys,re\n",
    "\n",
    "processed = open('Processed-anonymous-msweb.data', 'w')\n",
    "urls = open('urls.data', 'w')\n",
    "\n",
    "customer= \"00000\"\n",
    "with open (\"anonymous-msweb.data\", \"r\") as myfile:\n",
    "    for line in myfile.readlines():\n",
    "        line = line.strip()\n",
    "        #Keep track of the most recent customer ID\n",
    "        if(line[0]=='C'):\n",
    "            customer = line[line.rfind(\",\")::]\n",
    "            continue\n",
    "        #Output visit information joined with customer ID\n",
    "        if(line[0]=='V'):\n",
    "            processed.write(line+',C'+customer+'\\n')\n",
    "            continue\n",
    "        if(line[0]=='A'):\n",
    "            urls.write(line+\"\\n\")\n",
    "            \n",
    "processed.close()\n",
    "urls.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 4.3: Find the 5 most frequently visited pages using MrJob from the output of 4.2 (i.e., transfromed log file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting MRJob4_3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile MRJob4_3.py\n",
    "#!/usr/bin/python\n",
    "# MRJob4_3.py\n",
    "# Author: Jackson Lane\n",
    "# Description: MRJob code to find the 5 most frequently visited pages from the output of 4.2\n",
    "# Has two MR steps:\n",
    "# The first step aggregates the number of visits to each site\n",
    "# The second step get the top 5 sites with the most visits\n",
    "\n",
    "from mrjob.job import MRJob, MRStep\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "\n",
    "class MRJob4_3(MRJob):\n",
    "    \n",
    "    def mapper_visitcount(self, _, line):\n",
    "        # Passes on the page id and the visit count to the reducer \n",
    "        line = line.strip().split(\",\")\n",
    "        yield line[1], int(line[2])\n",
    "\n",
    "    def reducer_visitcount(self, pageID, counts):\n",
    "        # sums up the visit counts for each page\n",
    "        yield pageID, sum(counts)\n",
    "\n",
    "        \n",
    "    def reducer_top5_init(self):\n",
    "        # We want to maintain a counter to only print out the top 5 sites\n",
    "        self.currentrank = 5\n",
    "\n",
    "    def reducer_top5(self, pageID, visit_counts):\n",
    "        # Decrement counter and yield current site and visits\n",
    "        if self.currentrank > 0:\n",
    "            self.currentrank -= 1\n",
    "            yield pageID, sum(visit_counts)\n",
    "    \n",
    "    def steps(self):\n",
    "        return [MRStep(mapper=self.mapper_visitcount,reducer=self.reducer_visitcount),\n",
    "                MRStep(reducer_init=self.reducer_top5_init,reducer=self.reducer_top5,\n",
    "                jobconf={\n",
    "                    \"stream.num.map.output.key.fields\":\"2\",\n",
    "                    \"mapreduce.job.output.key.comparator.class\":\n",
    "                        \"org.apache.hadoop.mapred.lib.KeyFieldBasedComparator\",\n",
    "                    \"mapreduce.partition.keycomparator.options\":\"-k2,2nr\"\n",
    "                          })]\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    MRJob4_3.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PageID\tCount\n",
      "1008\t10836\n",
      "1034\t9383\n",
      "1004\t8463\n",
      "1018\t5330\n",
      "1017\t5108\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from MRJob4_3 import MRJob4_3\n",
    "\n",
    "mr_job = MRJob4_3(args=['Processed-anonymous-msweb.data','-r', 'hadoop', '--strict-protocols'])\n",
    "with mr_job.make_runner() as runner:\n",
    "    runner.run()\n",
    "    print (\"PageID\\tCount\")\n",
    "\n",
    "    for line in runner.stream_output():\n",
    "        line = mr_job.parse_output_line(line)\n",
    "        line=[str(i) for i in line]\n",
    "        print '\\t'.join(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 4.4: Find the most frequent visitor of each page using MrJob and the output of 4.2  (i.e., transfromed log file). In this output please include the webpage URL, webpageID and Visitor ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting MRJob4_4.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile MRJob4_4.py\n",
    "#!/usr/bin/python\n",
    "# MRJob4_4.py\n",
    "# Author: Jackson Lane\n",
    "# Description: MRJob code to find each site's most frequent visitor.\n",
    "# Has two MR steps:\n",
    "# The first step aggregates the number of visits to each site by each customer\n",
    "# The second step gets the top visitor for each site\n",
    "\n",
    "\n",
    "from mrjob.job import MRJob, MRStep\n",
    "import mrjob\n",
    "import csv\n",
    "import sys\n",
    "\n",
    "\n",
    "class MRJob4_4(MRJob):\n",
    "    \n",
    "    def mapper_visitcount(self, _, line):\n",
    "        # Passes on the page id and the visit count to the reducer \n",
    "        line = line.strip().split(\",\")\n",
    "        yield line[1]+\",\"+line[4],line[2]\n",
    "\n",
    "    def reducer_visitcount(self, keys, counts):\n",
    "        # sums up the visit counts for each page\n",
    "        pageID,visitorID = keys.split(\",\")\n",
    "        yield pageID, str(visitorID) +\"\\t\"+str(sum([int(i) for i in counts]))\n",
    "\n",
    "    # The reducer init here creates a dictionary with each site's URL\n",
    "    # It gets this data from the \"urls.data\" file sent to each reducer in the MRJob config\n",
    "    def reducer_top_init(self):\n",
    "        with open(\"urls.data\") as urls:\n",
    "            self.urls = {}\n",
    "            for line in urls.readlines():\n",
    "                fields = line.split(\",\")\n",
    "                self.urls[fields[1]] = \"www.microsoft.com\" + fields[4].strip().strip('\"') \n",
    "\n",
    "    def reducer_top(self, pageID, visitor):\n",
    "            yield self.urls[pageID]+\"\\t\"+pageID, visitor.next()\n",
    "    \n",
    "    def steps(self):\n",
    "        return [MRStep(mapper=self.mapper_visitcount,reducer=self.reducer_visitcount),\n",
    "                MRStep(reducer_init=self.reducer_top_init,reducer=self.reducer_top,\n",
    "                jobconf={\n",
    "                    \"stream.num.map.output.key.fields\":\"3\",\n",
    "                    \"mapreduce.job.output.key.comparator.class\":\n",
    "                        \"org.apache.hadoop.mapred.lib.KeyFieldBasedComparator\",\n",
    "                    \"mapreduce.partition.keycomparator.options\":\"-k3,3nr\"\n",
    "                          })]\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    MRJob4_4.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Driver Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL\t\t\t\tPageID\tVisitorID\tVisits\n",
      "www.microsoft.com/sitebuilder\t1026\t10016\t1\n",
      "www.microsoft.com/intdev\t1027\t10017\t1\n",
      "www.microsoft.com/oledev\t1028\t10017\t1\n",
      "www.microsoft.com/clipgallerylive\t1029\t10019\t1\n",
      "www.microsoft.com/ntserver\t1030\t10019\t1\n",
      "www.microsoft.com/msoffice\t1031\t10019\t1\n",
      "www.microsoft.com/games\t1032\t10019\t1\n",
      "www.microsoft.com/logostore\t1033\t10019\t1\n",
      "www.microsoft.com/ie\t1034\t10020\t1\n",
      "www.microsoft.com/windowssupport\t1035\t10021\t1\n",
      "www.microsoft.com/organizations\t1036\t10021\t1\n",
      "www.microsoft.com/windows95\t1037\t10021\t1\n",
      "www.microsoft.com/sbnmember\t1038\t10021\t1\n",
      "www.microsoft.com/isp\t1039\t10021\t1\n",
      "www.microsoft.com/office\t1040\t10021\t1\n",
      "www.microsoft.com/workshop\t1041\t10021\t1\n",
      "www.microsoft.com/vstudio\t1042\t10021\t1\n",
      "www.microsoft.com/smallbiz\t1043\t10021\t1\n",
      "www.microsoft.com/mediadev\t1044\t10024\t1\n",
      "www.microsoft.com/netmeeting\t1045\t10025\t1\n",
      "www.microsoft.com/iesupport\t1046\t10027\t1\n",
      "www.microsoft.com/publisher\t1048\t10030\t1\n",
      "www.microsoft.com/supportnet\t1049\t10031\t1\n",
      "www.microsoft.com/macoffice\t1050\t10032\t1\n",
      "www.microsoft.com/scheduleplus\t1051\t10035\t1\n",
      "www.microsoft.com/word\t1052\t10035\t1\n",
      "www.microsoft.com/visualj\t1053\t10035\t1\n",
      "www.microsoft.com/exchange\t1054\t10036\t1\n",
      "www.microsoft.com/kids\t1055\t10037\t1\n",
      "www.microsoft.com/sports\t1056\t10037\t1\n",
      "www.microsoft.com/powerpoint\t1057\t10038\t1\n",
      "www.microsoft.com/referral\t1058\t10039\t1\n",
      "www.microsoft.com/sverige\t1059\t10047\t1\n",
      "www.microsoft.com/msword\t1060\t10053\t1\n",
      "www.microsoft.com/promo\t1061\t10058\t1\n",
      "www.microsoft.com/msaccess\t1062\t10065\t1\n",
      "www.microsoft.com/intranet\t1063\t10067\t1\n",
      "www.microsoft.com/activeplatform\t1064\t10068\t1\n",
      "www.microsoft.com/java\t1065\t10068\t1\n",
      "www.microsoft.com/musicproducer\t1066\t10068\t1\n",
      "www.microsoft.com/frontpage\t1067\t10068\t1\n",
      "www.microsoft.com/vbscript\t1068\t10068\t1\n",
      "www.microsoft.com/windowsce\t1069\t10068\t1\n",
      "www.microsoft.com/activex\t1070\t10068\t1\n",
      "www.microsoft.com/automap\t1071\t10068\t1\n",
      "www.microsoft.com/vinterdev\t1072\t10068\t1\n",
      "www.microsoft.com/taiwan\t1073\t10078\t1\n",
      "www.microsoft.com/ntworkstation\t1074\t10085\t1\n",
      "www.microsoft.com/jobs\t1075\t10104\t1\n",
      "www.microsoft.com/ntwkssupport\t1076\t10107\t1\n",
      "www.microsoft.com/msofficesupport\t1077\t10109\t1\n",
      "www.microsoft.com/ntserversupport\t1078\t10122\t1\n",
      "www.microsoft.com/australia\t1079\t10122\t1\n",
      "www.microsoft.com/brasil\t1080\t10126\t1\n",
      "www.microsoft.com/accessdev\t1081\t10127\t1\n",
      "www.microsoft.com/access\t1082\t10127\t1\n",
      "www.microsoft.com/msaccesssupport\t1083\t10127\t1\n",
      "www.microsoft.com/uk\t1084\t10132\t1\n",
      "www.microsoft.com/exchangesupport\t1085\t10132\t1\n",
      "www.microsoft.com/oem\t1086\t10132\t1\n",
      "www.microsoft.com/proxy\t1087\t10132\t1\n",
      "www.microsoft.com/outlook\t1088\t10132\t1\n",
      "www.microsoft.com/officereference\t1089\t10132\t1\n",
      "www.microsoft.com/gamessupport\t1090\t10133\t1\n",
      "www.microsoft.com/hwdev\t1091\t10142\t1\n",
      "www.microsoft.com/vfoxpro\t1092\t10150\t1\n",
      "www.microsoft.com/vba\t1093\t10156\t1\n",
      "www.microsoft.com/mshome\t1094\t10156\t1\n",
      "www.microsoft.com/catalog\t1095\t10156\t1\n",
      "www.microsoft.com/mspress\t1096\t10156\t1\n",
      "www.microsoft.com/latam\t1097\t10156\t1\n",
      "www.microsoft.com/devonly\t1098\t10157\t1\n",
      "www.microsoft.com/cio\t1099\t10159\t1\n",
      "www.microsoft.com/education\t1100\t10165\t1\n",
      "www.microsoft.com/oledb\t1101\t10166\t1\n",
      "www.microsoft.com/homeessentials\t1102\t10168\t1\n",
      "www.microsoft.com/works\t1103\t10168\t1\n",
      "www.microsoft.com/hk\t1104\t10191\t1\n",
      "www.microsoft.com/france\t1105\t10197\t1\n",
      "www.microsoft.com/cze\t1106\t10198\t1\n",
      "www.microsoft.com/slovakia\t1107\t10198\t1\n",
      "www.microsoft.com/teammanager\t1108\t10205\t1\n",
      "www.microsoft.com/technet\t1109\t10205\t1\n",
      "www.microsoft.com/mastering\t1110\t10208\t1\n",
      "www.microsoft.com/ssafe\t1111\t10208\t1\n",
      "www.microsoft.com/canada\t1112\t10208\t1\n",
      "www.microsoft.com/security\t1113\t10215\t1\n",
      "www.microsoft.com/servad\t1114\t10216\t1\n",
      "www.microsoft.com/hun\t1115\t10216\t1\n",
      "www.microsoft.com/switzerland\t1116\t10225\t1\n",
      "www.microsoft.com/sidewinder\t1117\t10228\t1\n",
      "www.microsoft.com/sql\t1118\t10235\t1\n",
      "www.microsoft.com/corpinfo\t1119\t10240\t1\n",
      "www.microsoft.com/switch\t1120\t10241\t1\n",
      "www.microsoft.com/magazine\t1121\t10241\t1\n",
      "www.microsoft.com/mindshare\t1122\t10243\t1\n",
      "www.microsoft.com/germany\t1123\t10254\t1\n",
      "www.microsoft.com/industry\t1124\t10263\t1\n",
      "www.microsoft.com/imagecomposer\t1125\t10269\t1\n",
      "www.microsoft.com/mediamanager\t1126\t10272\t1\n",
      "www.microsoft.com/netshow\t1127\t10286\t1\n",
      "www.microsoft.com/msf\t1128\t10286\t1\n",
      "www.microsoft.com/ado\t1129\t10290\t1\n",
      "www.microsoft.com/syspro\t1130\t10306\t1\n",
      "www.microsoft.com/moneyzone\t1131\t10316\t1\n",
      "www.microsoft.com/msmoneysupport\t1132\t10316\t1\n",
      "www.microsoft.com/frontpagesupport\t1133\t10319\t1\n",
      "www.microsoft.com/backoffice\t1134\t10335\t1\n",
      "www.microsoft.com/mswordsupport\t1135\t10339\t1\n",
      "www.microsoft.com/usa\t1136\t10348\t1\n",
      "www.microsoft.com/mscorp\t1137\t10348\t1\n",
      "www.microsoft.com/mind\t1138\t10351\t1\n",
      "www.microsoft.com/k-12\t1139\t10362\t1\n",
      "www.microsoft.com/netherlands\t1140\t10363\t1\n",
      "www.microsoft.com/europe\t1141\t10372\t1\n",
      "www.microsoft.com/southafrica\t1142\t10372\t1\n",
      "www.microsoft.com/workshoop\t1143\t10381\t1\n",
      "www.microsoft.com/devnews\t1144\t10406\t1\n",
      "www.microsoft.com/vfoxprosupport\t1145\t10418\t1\n",
      "www.microsoft.com/msp\t1146\t10429\t1\n",
      "www.microsoft.com/msft\t1147\t10438\t1\n",
      "www.microsoft.com/channel_resources\t1148\t10468\t1\n",
      "www.microsoft.com/adc\t1149\t10471\t1\n",
      "www.microsoft.com/infoserv\t1150\t10473\t1\n",
      "www.microsoft.com/mspowerpointsupport\t1151\t10482\t1\n",
      "www.microsoft.com/rus\t1152\t10486\t1\n",
      "www.microsoft.com/venezuela\t1153\t10500\t1\n",
      "www.microsoft.com/project\t1154\t10564\t1\n",
      "www.microsoft.com/sidewalk\t1155\t10606\t1\n",
      "www.microsoft.com/powered\t1156\t10624\t1\n",
      "www.microsoft.com/win32dev\t1157\t10627\t1\n",
      "www.microsoft.com/imedia\t1158\t10632\t1\n",
      "www.microsoft.com/transaction\t1159\t10661\t1\n",
      "www.microsoft.com/visualcsupport\t1160\t10669\t1\n",
      "www.microsoft.com/workssupport\t1161\t10677\t1\n",
      "www.microsoft.com/infoservsupport\t1162\t10699\t1\n",
      "www.microsoft.com/opentype\t1163\t10744\t1\n",
      "www.microsoft.com/smsmgmt\t1164\t10752\t1\n",
      "www.microsoft.com/poland\t1165\t10784\t1\n",
      "www.microsoft.com/mexico\t1166\t10788\t1\n",
      "www.microsoft.com/hwtest\t1167\t10791\t1\n",
      "www.microsoft.com/salesinfo\t1168\t10797\t1\n",
      "www.microsoft.com/msproject\t1169\t10797\t1\n",
      "www.microsoft.com/mail\t1170\t10821\t1\n",
      "www.microsoft.com/merchant\t1171\t10828\t1\n",
      "www.microsoft.com/belgium\t1172\t10834\t1\n",
      "www.microsoft.com/moli\t1173\t10842\t1\n",
      "www.microsoft.com/nz\t1174\t10866\t1\n",
      "www.microsoft.com/msprojectsupport\t1175\t10888\t1\n",
      "www.microsoft.com/jscript\t1176\t10932\t1\n",
      "www.microsoft.com/events\t1177\t10951\t1\n",
      "www.microsoft.com/msdownload.\t1178\t11008\t1\n",
      "www.microsoft.com/colombia\t1179\t11027\t1\n",
      "www.microsoft.com/slovenija\t1180\t11035\t1\n",
      "www.microsoft.com/kidssupport\t1181\t11044\t1\n",
      "www.microsoft.com/fortran\t1182\t11090\t1\n",
      "www.microsoft.com/italy\t1183\t11111\t1\n",
      "www.microsoft.com/msexcelsupport\t1184\t11134\t1\n",
      "www.microsoft.com/sna\t1185\t11142\t1\n",
      "www.microsoft.com/college\t1186\t11150\t1\n",
      "www.microsoft.com/odbc\t1187\t11173\t1\n",
      "www.microsoft.com/korea\t1188\t11190\t1\n",
      "www.microsoft.com/internet\t1189\t11243\t1\n",
      "www.microsoft.com/repository\t1190\t11287\t1\n",
      "www.microsoft.com/management\t1191\t11331\t1\n",
      "www.microsoft.com/visualjsupport\t1192\t11359\t1\n",
      "www.microsoft.com/offdevsupport\t1193\t11367\t1\n",
      "www.microsoft.com/china\t1194\t11372\t1\n",
      "www.microsoft.com/portugal\t1195\t11429\t1\n",
      "www.microsoft.com/ie40\t1196\t11431\t1\n",
      "www.microsoft.com/sqlsupport\t1197\t11444\t1\n",
      "www.microsoft.com/pictureit\t1198\t11482\t1\n",
      "www.microsoft.com/feedback\t1199\t11644\t1\n",
      "www.microsoft.com/benelux\t1200\t11674\t1\n",
      "www.microsoft.com/hardware\t1201\t11800\t1\n",
      "www.microsoft.com/advtech\t1202\t11802\t1\n",
      "www.microsoft.com/danmark\t1203\t11806\t1\n",
      "www.microsoft.com/msscheduleplus\t1204\t11904\t1\n",
      "www.microsoft.com/hardwaresupport\t1205\t11917\t1\n",
      "www.microsoft.com/select\t1206\t12011\t1\n",
      "www.microsoft.com/icp\t1207\t12135\t1\n",
      "www.microsoft.com/israel\t1208\t12177\t1\n",
      "www.microsoft.com/turkey\t1209\t12239\t1\n",
      "www.microsoft.com/snasupport\t1210\t12359\t1\n",
      "www.microsoft.com/smsmgmtsupport\t1211\t12395\t1\n",
      "www.microsoft.com/worldwide\t1212\t12421\t1\n",
      "www.microsoft.com/corporate_solutions\t1213\t12472\t1\n",
      "www.microsoft.com/finserv\t1214\t12515\t1\n",
      "www.microsoft.com/developer\t1215\t12577\t1\n",
      "www.microsoft.com/vrml\t1216\t12666\t1\n",
      "www.microsoft.com/ireland\t1217\t12675\t1\n",
      "www.microsoft.com/publishersupport\t1218\t12714\t1\n",
      "www.microsoft.com/ads\t1219\t12746\t1\n",
      "www.microsoft.com/macofficesupport\t1220\t12795\t1\n",
      "www.microsoft.com/mstv\t1221\t12815\t1\n",
      "www.microsoft.com/msofc\t1222\t12819\t1\n",
      "www.microsoft.com/finland\t1223\t12828\t1\n",
      "www.microsoft.com/atec\t1224\t13041\t1\n",
      "www.microsoft.com/piracy\t1225\t13061\t1\n",
      "www.microsoft.com/msschedplussupport\t1226\t13179\t1\n",
      "www.microsoft.com/argentina\t1227\t13235\t1\n",
      "www.microsoft.com/vtest\t1228\t13266\t1\n",
      "www.microsoft.com/uruguay\t1229\t13510\t1\n",
      "www.microsoft.com/mailsupport\t1230\t13541\t1\n",
      "www.microsoft.com/win32devsupport\t1231\t13918\t1\n",
      "www.microsoft.com/standards\t1232\t13926\t1\n",
      "www.microsoft.com/vbscripts\t1233\t14363\t1\n",
      "www.microsoft.com/off97cat\t1234\t14418\t1\n",
      "www.microsoft.com/onlineeval\t1235\t14522\t1\n",
      "www.microsoft.com/globaldev\t1236\t14738\t1\n",
      "www.microsoft.com/devdays\t1237\t14764\t1\n",
      "www.microsoft.com/exceldev\t1238\t15247\t1\n",
      "www.microsoft.com/msconsult\t1239\t15361\t1\n",
      "www.microsoft.com/thailand\t1240\t15461\t1\n",
      "www.microsoft.com/india\t1241\t15820\t1\n",
      "www.microsoft.com/msgarden\t1242\t16289\t1\n",
      "www.microsoft.com/usability\t1243\t16904\t1\n",
      "www.microsoft.com/devwire\t1244\t16967\t1\n",
      "www.microsoft.com/ofc\t1245\t16999\t1\n",
      "www.microsoft.com/gamesdev\t1246\t17120\t1\n",
      "www.microsoft.com/wineguide\t1247\t18240\t1\n",
      "www.microsoft.com/softimage\t1248\t18347\t1\n",
      "www.microsoft.com/fortransupport\t1249\t18384\t1\n",
      "www.microsoft.com/middleeast\t1250\t18534\t1\n",
      "www.microsoft.com/referencesupport\t1251\t18941\t1\n",
      "www.microsoft.com/giving\t1252\t19483\t1\n",
      "www.microsoft.com/worddev\t1253\t19746\t1\n",
      "www.microsoft.com/ie3\t1254\t20190\t1\n",
      "www.microsoft.com/msmq\t1255\t20277\t1\n",
      "www.microsoft.com/sia\t1256\t20832\t1\n",
      "www.microsoft.com/devvideos\t1257\t21184\t1\n",
      "www.microsoft.com/peru\t1258\t21399\t1\n",
      "www.microsoft.com/controls\t1259\t21424\t1\n",
      "www.microsoft.com/trial\t1260\t21894\t1\n",
      "www.microsoft.com/diyguide\t1261\t22485\t1\n",
      "www.microsoft.com/chile\t1262\t24951\t1\n",
      "www.microsoft.com/services\t1263\t26122\t1\n",
      "www.microsoft.com/se_partners\t1264\t26801\t1\n",
      "www.microsoft.com/ssafesupport\t1265\t26811\t1\n",
      "www.microsoft.com/licenses\t1266\t26815\t1\n",
      "www.microsoft.com/caribbean\t1267\t27482\t1\n",
      "www.microsoft.com/javascript\t1268\t27503\t1\n",
      "www.microsoft.com/business\t1269\t28044\t1\n",
      "www.microsoft.com/developr\t1270\t28493\t1\n",
      "www.microsoft.com/mdsn\t1271\t28493\t1\n",
      "www.microsoft.com/softlib\t1272\t28493\t1\n",
      "www.microsoft.com/mdn\t1273\t28493\t1\n",
      "www.microsoft.com/pdc\t1274\t28493\t1\n",
      "www.microsoft.com/security.\t1275\t28903\t1\n",
      "www.microsoft.com/vtestsupport\t1276\t29654\t1\n",
      "www.microsoft.com/stream\t1277\t30111\t1\n",
      "www.microsoft.com/hed\t1278\t30460\t1\n",
      "www.microsoft.com/msgolf\t1279\t31062\t1\n",
      "www.microsoft.com/music\t1280\t33424\t1\n",
      "www.microsoft.com/intellimouse\t1281\t37099\t1\n",
      "www.microsoft.com/home\t1282\t39877\t1\n",
      "www.microsoft.com/cinemania\t1283\t41033\t1\n",
      "www.microsoft.com/partner\t1284\t41108\t1\n",
      "www.microsoft.com/train_cert\t1295\t10028\t1\n",
      "www.microsoft.com/regwiz\t1000\t10001\t1\n",
      "www.microsoft.com/support\t1001\t10001\t1\n",
      "www.microsoft.com/athome\t1002\t10001\t1\n",
      "www.microsoft.com/kb\t1003\t10002\t1\n",
      "www.microsoft.com/search\t1004\t10003\t1\n",
      "www.microsoft.com/norge\t1005\t10004\t1\n",
      "www.microsoft.com/misc\t1006\t10005\t1\n",
      "www.microsoft.com/ie_intl\t1007\t10007\t1\n",
      "www.microsoft.com/msdownload\t1008\t10009\t1\n",
      "www.microsoft.com/windows\t1009\t10009\t1\n",
      "www.microsoft.com/vbasic\t1010\t10010\t1\n",
      "www.microsoft.com/officedev\t1011\t10010\t1\n",
      "www.microsoft.com/outlookdev\t1012\t10010\t1\n",
      "www.microsoft.com/vbasicsupport\t1013\t10010\t1\n",
      "www.microsoft.com/officefreestuff\t1014\t10010\t1\n",
      "www.microsoft.com/msexcel\t1015\t10011\t1\n",
      "www.microsoft.com/excel\t1016\t10011\t1\n",
      "www.microsoft.com/products\t1017\t10011\t1\n",
      "www.microsoft.com/isapi\t1018\t10011\t1\n",
      "www.microsoft.com/mspowerpoint\t1019\t10011\t1\n",
      "www.microsoft.com/msdn\t1020\t10012\t1\n",
      "www.microsoft.com/visualc\t1021\t10012\t1\n",
      "www.microsoft.com/truetype\t1022\t10013\t1\n",
      "www.microsoft.com/spain\t1023\t10014\t1\n",
      "www.microsoft.com/iis\t1024\t10015\t1\n",
      "www.microsoft.com/gallery\t1025\t10016\t1\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from MRJob4_4 import MRJob4_4\n",
    "\n",
    "mr_job = MRJob4_4(args=['Processed-anonymous-msweb.data','r','hadoop', '--file',\"urls.data\",'--strict-protocols'])\n",
    "with mr_job.make_runner() as runner:\n",
    "    runner.run()\n",
    "    print 'URL\\t\\t\\t\\tPageID\\tVisitorID\\tVisits'\n",
    "    for line in runner.stream_output():\n",
    "        line =  mr_job.parse_output_line(line)\n",
    "        print '\\t'.join(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 4.5 Clustering Tweet Dataset\n",
    "\n",
    "Here you will use a different dataset consisting of word-frequency distributions \n",
    "for 1,000 Twitter users. These Twitter users use language in very different ways,\n",
    "and were classified by hand according to the criteria:\n",
    "\n",
    "0: Human, where only basic human-human communication is observed.\n",
    "\n",
    "1: Cyborg, where language is primarily borrowed from other sources\n",
    "(e.g., jobs listings, classifieds postings, advertisements, etc...).\n",
    "\n",
    "2: Robot, where language is formulaically derived from unrelated sources\n",
    "(e.g., weather/seismology, police/fire event logs, etc...).\n",
    "\n",
    "3: Spammer, where language is replicated to high multiplicity\n",
    "(e.g., celebrity obsessions, personal promotion, etc... )\n",
    "\n",
    "Using this data, you will implement a 1000-dimensional K-means algorithm in MrJob on the users\n",
    "by their 1000-dimensional word stripes/vectors using several \n",
    "centroid initializations and values of K.\n",
    "\n",
    "Note that each \"point\" is a user as represented by 1000 words, and that\n",
    "word-frequency distributions are generally heavy-tailed power-laws\n",
    "(often called Zipf distributions), and are very rare in the larger class\n",
    "of discrete, random distributions. For each user you will have to normalize\n",
    "by its \"TOTAL\" column. Try several parameterizations and initializations:\n",
    "\n",
    "(A) K=4 uniform random centroid-distributions over the 1000 words (generate 1000 random numbers and normalize the vectors)\n",
    "(B) K=2 perturbation-centroids, randomly perturbed from the aggregated (user-wide) distribution \n",
    "(C) K=4 perturbation-centroids, randomly perturbed from the aggregated (user-wide) distribution \n",
    "(D) K=4 \"trained\" centroids, determined by the sums across the classes. Use use the \n",
    "(row-normalized) class-level aggregates as 'trained' starting centroids (i.e., the training is already done for you!).\n",
    "Note that you do not have to compute the aggregated distribution or the \n",
    "class-aggregated distributions, which are rows in the auxiliary file:\n",
    "\n",
    "For experiments A, B, C and D and iterate until a threshold (try 0.001) is reached.\n",
    "After convergence, print out a summary of the classes present in each cluster.\n",
    "In particular, report the composition as measured by the total\n",
    "portion of each class type (0-3) contained in each cluster,\n",
    "and discuss your findings and any differences in outcomes across parts A-D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Kmeans.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Kmeans.py\n",
    "# Kmeans code takan from Week 5 Readings\n",
    "# Modified to accommodate 1000 fields instead of 4\n",
    "# And to take variable k\n",
    "# And to drop first 3 fields from input lines\n",
    "\n",
    "from numpy import argmin, array, random\n",
    "from mrjob.job import MRJob, MRStep\n",
    "from itertools import chain\n",
    "\n",
    "#Calculate find the nearest centroid for data point \n",
    "def MinDist(datapoint, centroid_points):\n",
    "    datapoint = array(datapoint)\n",
    "    centroid_points = array(centroid_points)\n",
    "    diff = datapoint - centroid_points \n",
    "    diffsq = diff*diff\n",
    "    # Get the nearest centroid for each instance\n",
    "    minidx = argmin(list(diffsq.sum(axis = 1)))\n",
    "    return minidx\n",
    "\n",
    "#Check whether centroids converge\n",
    "def stop_criterion(centroid_points_old, centroid_points_new,T):\n",
    "    oldvalue = list(chain(*centroid_points_old))\n",
    "    newvalue = list(chain(*centroid_points_new))\n",
    "    Diff = [abs(x-y) for x, y in zip(oldvalue, newvalue)]\n",
    "    Flag = True\n",
    "    for i in Diff:\n",
    "        if(i>T):\n",
    "            Flag = False\n",
    "            break\n",
    "    return Flag\n",
    "\n",
    "class MRKmeans(MRJob):\n",
    "    centroid_points=[]\n",
    "    k=4    \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper_init = self.mapper_init, mapper=self.mapper,combiner = self.combiner,reducer=self.reducer)\n",
    "               ]\n",
    "    def mapper_init(self):\n",
    "        #load centroids info from file\n",
    "        self.centroid_points = [map(float,s.split('\\n')[0].split(',')) for s in open(\"Centroids.txt\").readlines()]\n",
    "        self.k = len(self.centroid_points)\n",
    "    #Mapper to assign each tweet to the closest centroid\n",
    "    def mapper(self, _, line):\n",
    "        line =line.split(\",\")\n",
    "        D = map(float,line[3:])\n",
    "        yield int(MinDist(D,self.centroid_points)), [D,1]\n",
    "    #Combine sum of data points locally\n",
    "    def combiner(self, idx, inputdata):\n",
    "        sums = [0 for i in range(1000)]\n",
    "        num = 0\n",
    "        for D,n in inputdata:\n",
    "            num = num + n\n",
    "            sums = [sums[i] + int(D[i]) for i in range(1000)]\n",
    "        yield idx,(sums,num)\n",
    "    #Aggregate sum for each cluster and then calculate the new centroids\n",
    "    def reducer(self, idx, inputdata): \n",
    "        centroids = [[float(0)]*1000] * self.k\n",
    "        num = [0]*self.k \n",
    "        for D, n in inputdata:\n",
    "            num[idx] = num[idx] + n\n",
    "            centroids[idx] = [centroids[idx][i] + D[i] for i in range(1000)]\n",
    "        for i in range(1000):\n",
    "            centroids[idx][i] = centroids[idx][i]/num[idx]\n",
    "        yield idx,centroids[idx]\n",
    "      \n",
    "if __name__ == '__main__':\n",
    "    MRKmeans.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Functions to generate the different types of centroid point\n",
    "\n",
    "# The below was taken from the homework instructions.  \n",
    "# I changed the name of the function to \"perturbed\" for clarity\n",
    "\n",
    "###################################################################################\n",
    "##Geneate random initial centroids around the global aggregate\n",
    "##Part (B) and (C) of this question\n",
    "###################################################################################\n",
    "def perturbed(k):\n",
    "    counter = 0\n",
    "    for line in open(\"topUsers_Apr-Jul_2014_1000-words_summaries.txt\").readlines():\n",
    "        if counter == 2:        \n",
    "            data = re.split(\",\",line)\n",
    "            globalAggregate = [float(data[i+3])/float(data[2]) for i in range(1000)]\n",
    "        counter += 1\n",
    "    #perturb the global aggregate for the four initializations    \n",
    "    centroids = []\n",
    "    for i in range(k):\n",
    "        rndpoints = random.sample(1000)\n",
    "        peturpoints = [rndpoints[n]/10+globalAggregate[n] for n in range(1000)]\n",
    "        centroids.append(peturpoints)\n",
    "        total = 0    # We need to find the data-wide centroid first\n",
    "    # Add random noise to this data-wide centroid to get the second centroi\n",
    "        for j in range(len(centroids[i])):\n",
    "            total += centroids[i][j]\n",
    "        for j in range(len(centroids[i])):\n",
    "            centroids[i][j] = centroids[i][j]/total\n",
    "    return centroids\n",
    "\n",
    "# Function to generate uniform centroids.\n",
    "# Pick k random tweets from the corpus to serve as our inital centroids\n",
    "def uniform(k):\n",
    "        data=[]\n",
    "        with open('topUsers_Apr-Jul_2014_1000-words.txt', 'r') as myfile:\n",
    "            for line in myfile.readlines():\n",
    "                line = line.strip()\n",
    "                line = line.split(\",\")\n",
    "                # Collect the word count fields into an array\n",
    "                data.append(line[3:])\n",
    "        #We now randomly select k tweets to be our centroids\n",
    "        return [map(int,data[random.randint(0,1000)]) for i in range(k)]\n",
    "\n",
    "# Function to get the trained centroids from the 1000 word summaries file\n",
    "def trained(k):\n",
    "    with open('topUsers_Apr-Jul_2014_1000-words_summaries.txt','r') as myfile:\n",
    "        centroids = []\n",
    "        #Skip first two lines (column names and totals)\n",
    "        myfile.readline()\n",
    "        myfile.readline()\n",
    "        \n",
    "        #The remaining four lines in the summaries text file correspond to\n",
    "        #the word counts for each of the four types of users.\n",
    "        for line in myfile.readlines():\n",
    "            line = line.strip()\n",
    "            line = line.split(\",\")\n",
    "            # Get the per tweet average for each of the word counts\n",
    "            point = [int(i)/float(line[2]) for i in line[3:]]\n",
    "            centroids.append(point)\n",
    "        # Return only the first k of the centroids \n",
    "        return centroids[:k]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Functions to report the goodness of fit and purity of the generated k-means clusters\n",
    "\n",
    "#Reuse the MinDist function from the KMeans MRJob\n",
    "def MinDist(datapoint, centroid_points):\n",
    "    datapoint = array(datapoint)\n",
    "    centroid_points = array(centroid_points)\n",
    "    diff = datapoint - centroid_points \n",
    "    diffsq = diff*diff\n",
    "    # Get the nearest centroid for each instance\n",
    "    minidx = argmin(list(diffsq.sum(axis = 1)))\n",
    "    return minidx\n",
    "\n",
    "\n",
    "def reportPurity(centroids,k):\n",
    "    # Confusion matrix and summary variables\n",
    "    confuse_matrix = [[0 for x in range(k)] for y in range(4)]\n",
    "    predicted_counts = [0 for x in range(k)]\n",
    "    actual_counts = [0 for x in range(4)]\n",
    "    # Assign each tweet to the closest cluster, check if cluster matches actual code\n",
    "    with open('topUsers_Apr-Jul_2014_1000-words.txt') as myfile:\n",
    "        for line in myfile.readlines():\n",
    "            line = line.strip().split(\",\")\n",
    "            # As before, ignore the first three fields and only consider the actual word count fields\n",
    "            tweet = [float(i) for i in line[3:]]\n",
    "            # Get the closest cluster\n",
    "            predicted = int(MinDist(tweet, centroids))\n",
    "            # Get which code the tweet actually belongs to\n",
    "            actual = int(line[1])\n",
    "            # Update the confusion matrix and totals\n",
    "            confuse_matrix[actual][predicted] += 1\n",
    "            predicted_counts[predicted] += 1\n",
    "            actual_counts[actual] += 1\n",
    "    \n",
    "    # With confusion matrix and prediction counts, calculate purity\n",
    "    purity = sum([max([confuse_matrix[i][j] for i in range(4)])  for j in range(k)])/float(sum(predicted_counts))\n",
    "\n",
    "            \n",
    "    # Print out the findings  \n",
    "    labels = [\"Human\",\"Cyborg\",\"Robot\",\"Spammer\"]\n",
    "    print \"\\tCluster ID\"\n",
    "    print \"Actual\\t|\\t\" +'\\t'.join(map(str,range(k))) + \"\\t|Total\"\n",
    "    print \"---------------------------------------------------------------\"\n",
    "    for i in range(4):\n",
    "        print labels[i] + '\\t|\\t'+ '\\t'.join(map(str,confuse_matrix[i])) + \"\\t|\" + str(actual_counts[i])\n",
    "    print \"---------------------------------------------------------------\"\n",
    "    print \"Total\\t|\\t\" + \"\\t\".join(map(str,predicted_counts))\n",
    "\n",
    "    print \n",
    "    print \"Purity Score:\",purity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Driver class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Since we'll need to run this 4 times, I've turned the driver code from the Week 5 Kmeans code into its own reusable function.  \n",
    "from numpy import random\n",
    "from Kmeans import MRKmeans, stop_criterion\n",
    "mr_job = MRKmeans(args=['topUsers_Apr-Jul_2014_1000-words.txt', '-r', 'hadoop','--file', 'Centroids.txt', '--file','topUsers_Apr-Jul_2014_1000-words.txt'])\n",
    "\n",
    "\n",
    "\n",
    "def run_kmeans(centroid_type, k):\n",
    "    \n",
    "    \n",
    "    # First we have to generate the centroid points.  \n",
    "    centroid_points = eval(centroid_type+\"(\"+str(k)+\")\")\n",
    "    num = []\n",
    "                        \n",
    "    with open('Centroids.txt', 'w+') as myfile:\n",
    "            myfile.writelines(','.join(str(j) for j in i) + '\\n' for i in centroid_points)\n",
    "            \n",
    "    # Update centroids iteratively    \n",
    "    i = 0\n",
    "    while(1):\n",
    "        # save previous centoids to check convergency\n",
    "        centroid_points_old = centroid_points[:]\n",
    "        with mr_job.make_runner() as runner: \n",
    "            runner.run()\n",
    "            # stream_output: get access of the output \n",
    "            for line in runner.stream_output():\n",
    "                key,value =  mr_job.parse_output_line(line)\n",
    "                centroid_points[key] = value\n",
    "        i = i + 1\n",
    "        if(stop_criterion(centroid_points_old,centroid_points,0.01)):\n",
    "            break\n",
    "        with open('Centroids.txt', 'w+') as myfile:\n",
    "            myfile.writelines(','.join(str(j) for j in i) + '\\n' for i in centroid_points)\n",
    "    print \"Convergence after\", i, \"iterations\"\n",
    "    \n",
    "    #Report the purity and summary\n",
    "    reportPurity(centroid_points,k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence after 17 iterations\n",
      "\tCluster ID\n",
      "Actual\t|\t0\t1\t2\t3\t|Total\n",
      "---------------------------------------------------------------\n",
      "Human\t|\t0\t0\t0\t752\t|752\n",
      "Cyborg\t|\t26\t12\t4\t49\t|91\n",
      "Robot\t|\t3\t10\t4\t37\t|54\n",
      "Spammer\t|\t0\t0\t0\t103\t|103\n",
      "---------------------------------------------------------------\n",
      "Total\t|\t29\t22\t8\t941\n",
      "\n",
      "Purity Score: 0.794\n"
     ]
    }
   ],
   "source": [
    "run_kmeans(\"uniform\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence after 11 iterations\n",
      "\tCluster ID\n",
      "Actual\t|\t0\t1\t|Total\n",
      "---------------------------------------------------------------\n",
      "Human\t|\t752\t0\t|752\n",
      "Cyborg\t|\t76\t15\t|91\n",
      "Robot\t|\t45\t9\t|54\n",
      "Spammer\t|\t103\t0\t|103\n",
      "---------------------------------------------------------------\n",
      "Total\t|\t976\t24\n",
      "\n",
      "Purity Score: 0.767\n"
     ]
    }
   ],
   "source": [
    "run_kmeans(\"perturbed\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence after 24 iterations\n",
      "\tCluster ID\n",
      "Actual\t|\t0\t1\t2\t3\t|Total\n",
      "---------------------------------------------------------------\n",
      "Human\t|\t0\t0\t752\t0\t|752\n",
      "Cyborg\t|\t4\t0\t50\t37\t|91\n",
      "Robot\t|\t4\t4\t44\t2\t|54\n",
      "Spammer\t|\t0\t0\t103\t0\t|103\n",
      "---------------------------------------------------------------\n",
      "Total\t|\t8\t4\t949\t39\n",
      "\n",
      "Purity Score: 0.797\n"
     ]
    }
   ],
   "source": [
    "run_kmeans(\"perturbed\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5 D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convergence after 19 iterations\n",
      "\tCluster ID\n",
      "Actual\t|\t0\t1\t2\t3\t|Total\n",
      "---------------------------------------------------------------\n",
      "Human\t|\t752\t0\t0\t0\t|752\n",
      "Cyborg\t|\t31\t13\t0\t47\t|91\n",
      "Robot\t|\t40\t3\t4\t7\t|54\n",
      "Spammer\t|\t103\t0\t0\t0\t|103\n",
      "---------------------------------------------------------------\n",
      "Total\t|\t926\t16\t4\t54\n",
      "\n",
      "Purity Score: 0.816\n"
     ]
    }
   ],
   "source": [
    "run_kmeans(\"trained\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Discussion\n",
    "\n",
    "The trained centroids has the best Purity Score, which makes sense as the trained centroids were derived formulaically from the \"training\" data itself, the corpus of tweets.  But this means that the scores from trained centroids will probably not be generalizable if we apply these clusters to a different cluster, as it's likely the trained centroids are an overfitting of the training data.  \n",
    "\n",
    "The other three types of centroids were all generated with some randomness and thus have lower purity scores than the trained centroids, but their scores will likely be more generalizable than those of the trained centroids to different corpuses.  The centroids generated with k=2 in particular has a lower purity because it's trying to put 4 different types of data into just two clusters, so 100% purity is mathematically impossible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
